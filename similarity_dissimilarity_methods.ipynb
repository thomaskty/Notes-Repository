{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyO10C54lGvJmEhg9yl74QHq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### Euclidean"],"metadata":{"id":"CB2VKQuozMqM"}},{"cell_type":"code","source":["import numpy as np\n","from scipy.spatial.distance import mahalanobis\n","\n","# 1. Euclidean Distance\n","\n","def euclidean_distance(point1, point2):\n","    \"\"\"Calculate the Euclidean distance between two points.\"\"\"\n","    return np.sqrt(np.sum((np.array(point1) - np.array(point2))**2))\n","\n","# Example\n","p1, p2 = [109, 2,8], [4, 6,7]\n","print(f\"Euclidean Distance: {euclidean_distance(p1, p2):.2f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ItxDhjKazKGF","executionInfo":{"status":"ok","timestamp":1734190386670,"user_tz":-330,"elapsed":353,"user":{"displayName":"Thomaskutty Reji","userId":"11414883861734084745"}},"outputId":"6f90f030-ef4b-46dd-ab0e-c8be52a1f4a4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Euclidean Distance: 105.08\n"]}]},{"cell_type":"markdown","source":["### Cosine Similarity"],"metadata":{"id":"HT2NxNQuzZHE"}},{"cell_type":"code","source":["\n","# 2. Cosine Similarity\n","\n","def cosine_similarity(vec1, vec2):\n","    \"\"\"Calculate the cosine similarity between two vectors.\"\"\"\n","    vec1, vec2 = np.array(vec1), np.array(vec2)\n","    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n","\n","# Example\n","v1, v2 = [1, 0, -1], [-1, 0, 1]\n","print(f\"Cosine Similarity: {cosine_similarity(v1, v2):.2f}\")\n"],"metadata":{"id":"L3RI-rXuzKDw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Mahalanobis Distance"],"metadata":{"id":"R3YRYFqdzes3"}},{"cell_type":"code","source":["# 3. Mahalanobis Distance\n","\n","def mahalanobis_distance(point1, point2, cov_matrix):\n","    \"\"\"Calculate the Mahalanobis distance between two points.\"\"\"\n","    diff = np.array(point1) - np.array(point2)\n","    inv_cov_matrix = np.linalg.inv(cov_matrix)\n","    return np.sqrt(np.dot(np.dot(diff.T, inv_cov_matrix), diff))\n","\n","# Example\n","data_points = np.array([[1, 2], [3, 4], [5, 6]])\n","cov_matrix = np.cov(data_points, rowvar=False)\n","p1, p2 = [1, 2], [5, 6]\n","print(f\"Mahalanobis Distance: {mahalanobis_distance(p1, p2, cov_matrix):.2f}\")\n"],"metadata":{"id":"LjRxGNuxzKBZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Jaccard Similarity"],"metadata":{"id":"kiWIY4z0zk3r"}},{"cell_type":"code","source":["# 4. Jaccard Similarity\n","\n","def jaccard_similarity(set1, set2):\n","    \"\"\"Calculate the Jaccard similarity between two sets.\"\"\"\n","    set1, set2 = set(set1), set(set2)\n","    intersection = len(set1.intersection(set2))\n","    union = len(set1.union(set2))\n","    return intersection / union\n","\n","# Example\n","s1, s2 = {1, 2, 3}, {2, 3, 4}\n","print(f\"Jaccard Similarity: {jaccard_similarity(s1, s2):.2f}\")\n"],"metadata":{"id":"gSyRxB90zJ-j"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###  Hamming Distance"],"metadata":{"id":"ElsGEpJVzuWc"}},{"cell_type":"code","source":["# 5. Hamming Distance\n","\n","def hamming_distance(str1, str2):\n","    \"\"\"Calculate the Hamming distance between two strings.\"\"\"\n","    if len(str1) != len(str2):\n","        raise ValueError(\"Strings must be of the same length\")\n","    return sum(ch1 != ch2 for ch1, ch2 in zip(str1, str2))\n","\n","# Example\n","str1, str2 = \"karolin\", \"kathrin\"\n","print(f\"Hamming Distance: {hamming_distance(str1, str2)}\")\n"],"metadata":{"id":"Aftji2L_zJ5m"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Manhattan Distance"],"metadata":{"id":"oRusXyn7zx1W"}},{"cell_type":"code","source":["# 6. Manhattan Distance\n","\n","def manhattan_distance(point1, point2):\n","    \"\"\"Calculate the Manhattan distance between two points.\"\"\"\n","    return np.sum(np.abs(np.array(point1) - np.array(point2)))\n","\n","# Example\n","p1, p2 = [1, 2], [4, 6]\n","print(f\"Manhattan Distance: {manhattan_distance(p1, p2):.2f}\")\n"],"metadata":{"id":"LrsLKzD7zJ2u"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Minkowski Distance"],"metadata":{"id":"CF0sPg_Rz11m"}},{"cell_type":"code","source":["# 7. Minkowski Distance\n","\n","def minkowski_distance(point1, point2, p):\n","    \"\"\"Calculate the Minkowski distance between two points for a given p.\"\"\"\n","    return np.power(np.sum(np.abs(np.array(point1) - np.array(point2))**p), 1/p)\n","\n","# Example\n","p1, p2 = [1, 2], [4, 6]\n","print(f\"Minkowski Distance (p=3): {minkowski_distance(p1, p2, 3):.2f}\")"],"metadata":{"id":"fXegZ6jWzJzo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Chebyshev Distance"],"metadata":{"id":"DYRzo266z6gC"}},{"cell_type":"code","source":["# 8. Chebyshev Distance\n","\n","def chebyshev_distance(point1, point2):\n","    \"\"\"Calculate the Chebyshev distance between two points.\"\"\"\n","    return np.max(np.abs(np.array(point1) - np.array(point2)))\n","\n","# Example\n","p1, p2 = [1, 2], [4, 6]\n","print(f\"Chebyshev Distance: {chebyshev_distance(p1, p2):.2f}\")\n"],"metadata":{"id":"81LuI6_fz0QS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Bray-Curtis Dissimilarity"],"metadata":{"id":"asdbULIuz_zG"}},{"cell_type":"code","source":["# 9. Bray-Curtis Dissimilarity\n","\n","def bray_curtis_dissimilarity(vec1, vec2):\n","    \"\"\"Calculate the Bray-Curtis dissimilarity between two vectors.\"\"\"\n","    vec1, vec2 = np.array(vec1), np.array(vec2)\n","    return np.sum(np.abs(vec1 - vec2)) / np.sum(np.abs(vec1 + vec2))\n","\n","# Example\n","v1, v2 = [1, 2, 3], [4, 5, 6]\n","print(f\"Bray-Curtis Dissimilarity: {bray_curtis_dissimilarity(v1, v2):.2f}\")\n"],"metadata":{"id":"SFJj6wqLz-Mh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Correlation Methods : Pearson,Spearman, KendalTau"],"metadata":{"id":"Nrhs6gAh0D8_"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0HuW2gs5ysa2","executionInfo":{"status":"ok","timestamp":1734190868344,"user_tz":-330,"elapsed":316,"user":{"displayName":"Thomaskutty Reji","userId":"11414883861734084745"}},"outputId":"3d1bfc66-e0ab-4b8f-de29-8fb7d4ea7a0f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Pearson Correlation Coefficient: 0.40\n","Spearman Correlation Coefficient: 0.40\n","Kendall Tau Correlation: 0.33\n"]}],"source":["# 10. Pearson Correlation Coefficient\n","\n","def pearson_correlation(vec1, vec2):\n","    \"\"\"Calculate the Pearson correlation coefficient between two vectors.\"\"\"\n","    vec1, vec2 = np.array(vec1), np.array(vec2)\n","    mean1, mean2 = np.mean(vec1), np.mean(vec2)\n","    numerator = np.sum((vec1 - mean1) * (vec2 - mean2))\n","    denominator = np.sqrt(np.sum((vec1 - mean1)**2) * np.sum((vec2 - mean2)**2))\n","    return numerator / denominator\n","\n","# Example\n","v1, v2 = [1, 2, 3, 4], [1, 5, 7, 3]\n","print(f\"Pearson Correlation Coefficient: {pearson_correlation(v1, v2):.2f}\")\n","\n","# 11. Spearman Correlation Coefficient\n","\n","def spearman_correlation(vec1, vec2):\n","    \"\"\"Calculate the Spearman correlation coefficient between two vectors.\"\"\"\n","    vec1, vec2 = np.array(vec1), np.array(vec2)\n","    rank_vec1 = np.argsort(np.argsort(vec1))\n","    rank_vec2 = np.argsort(np.argsort(vec2))\n","    return pearson_correlation(rank_vec1, rank_vec2)\n","\n","# Example\n","v1, v2 = [1, 2, 3, 4], [1, 5, 7, 3]\n","print(f\"Spearman Correlation Coefficient: {spearman_correlation(v1, v2):.2f}\")\n","\n","# 12. Kendall Tau Correlation\n","\n","def kendall_tau_correlation(vec1, vec2):\n","    \"\"\"Calculate the Kendall Tau correlation coefficient between two vectors.\"\"\"\n","    vec1, vec2 = np.array(vec1), np.array(vec2)\n","    n = len(vec1)\n","    concordant, discordant = 0, 0\n","    for i in range(n):\n","        for j in range(i + 1, n):\n","            concordant += (vec1[i] - vec1[j]) * (vec2[i] - vec2[j]) > 0\n","            discordant += (vec1[i] - vec1[j]) * (vec2[i] - vec2[j]) < 0\n","    return (concordant - discordant) / (0.5 * n * (n - 1))\n","\n","# Example\n","v1, v2 = [1, 2, 3, 4], [1, 5, 7, 3]\n","print(f\"Kendall Tau Correlation: {kendall_tau_correlation(v1, v2):.2f}\")\n"]},{"cell_type":"code","source":["import numpy as np\n","from scipy.stats import pearsonr, kendalltau, spearmanr\n","\n","def calculate_trend(data_row):\n","    \"\"\"\n","    Calculate Pearson, Kendall, and Spearman correlations to assess trend in a data row.\n","\n","    Parameters:\n","    - data_row (list or np.array): A 1D list or array of numerical values.\n","\n","    Returns:\n","    - dict: Dictionary containing the correlation coefficients and p-values for each method.\n","    \"\"\"\n","    # Generate indices (e.g., time or order)\n","    indices = np.arange(1, len(data_row) + 1)\n","\n","    # Ensure the data row is a numpy array\n","    data_row = np.array(data_row)\n","\n","    # Compute correlations\n","    pearson_corr, pearson_p = pearsonr(indices, data_row)\n","    kendall_corr, kendall_p = kendalltau(indices, data_row)\n","    spearman_corr, spearman_p = spearmanr(indices, data_row)\n","\n","    # Return results as a dictionary\n","    return {\n","        \"Pearson\": {\"correlation\": pearson_corr, \"p-value\": pearson_p},\n","        \"Kendall\": {\"correlation\": kendall_corr, \"p-value\": kendall_p},\n","        \"Spearman\": {\"correlation\": spearman_corr, \"p-value\": spearman_p},\n","    }\n","\n","# Example usage:\n","data_row = [3, 5, 7, 6, 8, 9]\n","trend = calculate_trend(data_row)\n","from pprint import pprint\n","pprint(trend)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AIpevCH_ugbi","executionInfo":{"status":"ok","timestamp":1734373708814,"user_tz":-330,"elapsed":630,"user":{"displayName":"Thomaskutty Reji","userId":"11414883861734084745"}},"outputId":"2ea7c1b2-b545-490a-a8a2-ee1abcd5312d"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["{'Kendall': {'correlation': 0.8666666666666666,\n","             'p-value': 0.016666666666666666},\n"," 'Pearson': {'correlation': 0.9402561526802476,\n","             'p-value': 0.005247368266448161},\n"," 'Spearman': {'correlation': 0.942857142857143,\n","              'p-value': 0.004804664723032055}}\n"]}]},{"cell_type":"markdown","source":["## Gower Score"],"metadata":{"id":"-fVL9jc21L9G"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from scipy.spatial.distance import cdist\n","\n","def gower_distance_df(X_df, Y_df=None):\n","    \"\"\"\n","    Compute Gower's distance between two datasets (X_df, Y_df).\n","\n","    Parameters:\n","        X_df : pandas DataFrame, shape (n_samples, n_features)\n","            First data matrix (numerical and categorical).\n","        Y_df : pandas DataFrame, shape (m_samples, n_features), optional\n","            Second data matrix. If None, pairwise distance with X_df is computed.\n","\n","    Returns:\n","        dist : array-like, shape (n_samples, m_samples)\n","            Gower distance matrix.\n","    \"\"\"\n","    # Separate numerical and categorical columns\n","    num_cols = X_df.select_dtypes(include=[np.number]).columns\n","    cat_cols = X_df.select_dtypes(exclude=[np.number]).columns\n","\n","    # Function to compute Gower distance for numerical features\n","    def numerical_distance(a, b):\n","        # Add epsilon to avoid division by zero\n","        range_val = np.max([a, b]) - np.min([a, b])\n","        range_val = range_val if range_val > 0 else 1e-6  # Avoid zero range\n","        return np.abs(a - b) / range_val\n","\n","    # Function to compute Gower distance for categorical features\n","    def categorical_distance(a, b):\n","        return 0 if a == b else 1\n","\n","    # Function to compute Gower distance between two samples\n","    def gower_single(x, y):\n","        # Convert numpy arrays (rows) into pandas Series to index by column names\n","        x_series = pd.Series(x, index=X_df.columns)\n","        y_series = pd.Series(y, index=X_df.columns)\n","\n","        total_distance = 0\n","        # Calculate numerical distance\n","        for col in num_cols:\n","            total_distance += numerical_distance(x_series[col], y_series[col])\n","\n","        # Calculate categorical distance\n","        for col in cat_cols:\n","            total_distance += categorical_distance(x_series[col], y_series[col])\n","\n","        # Normalize by the number of features\n","        total_distance /= len(num_cols) + len(cat_cols)\n","        return total_distance\n","\n","    # Apply cdist to compute pairwise Gower distance\n","    dist_matrix = cdist(X_df.values, Y_df.values if Y_df is not None else X_df.values, metric=lambda u, v: gower_single(u, v))\n","\n","    return dist_matrix\n","\n","# Create a sample dataset with both numerical and categorical features\n","data = {\n","    'age': [25, 35, 45, 55, 65, 22, 28, 40, 50, 60],\n","    'income': [30000, 40000, 50000, 60000, 70000, 32000, 34000, 45000, 54000, 65000],\n","    'product_type': ['A', 'B', 'A', 'B', 'A', 'C', 'A', 'C', 'B', 'C'],\n","    'account_status': ['active', 'inactive', 'active', 'inactive', 'active', 'active', 'inactive', 'active', 'inactive', 'active']\n","}\n","\n","# Convert the data into a pandas DataFrame\n","df = pd.DataFrame(data)\n","\n","# Compute the Gower distance matrix\n","gower_distance_matrix = gower_distance_df(df)\n","\n","# Display the Gower distance matrix\n","print(\"Gower Distance Matrix:\")\n","print(gower_distance_matrix)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SC05yQvo0Lpr","executionInfo":{"status":"ok","timestamp":1734190835562,"user_tz":-330,"elapsed":2422,"user":{"displayName":"Thomaskutty Reji","userId":"11414883861734084745"}},"outputId":"a8c160b1-caf3-4809-af71-f622581b891c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Gower Distance Matrix:\n","[[0.   1.   0.5  1.   0.5  0.75 0.75 0.75 1.   0.75]\n"," [1.   0.   1.   0.5  1.   1.   0.75 1.   0.5  1.  ]\n"," [0.5  1.   0.   1.   0.5  0.75 0.75 0.75 1.   0.75]\n"," [1.   0.5  1.   0.   1.   1.   0.75 1.   0.5  1.  ]\n"," [0.5  1.   0.5  1.   0.   0.75 0.75 0.75 1.   0.75]\n"," [0.75 1.   0.75 1.   0.75 0.   1.   0.5  1.   0.5 ]\n"," [0.75 0.75 0.75 0.75 0.75 1.   0.   1.   0.75 1.  ]\n"," [0.75 1.   0.75 1.   0.75 0.5  1.   0.   1.   0.5 ]\n"," [1.   0.5  1.   0.5  1.   1.   0.75 1.   0.   1.  ]\n"," [0.75 1.   0.75 1.   0.75 0.5  1.   0.5  1.   0.  ]]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"TZcGTlQE0LnW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"bj2COJ080Lk_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"QRyUf44w0Li6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"6M85dmj_0LgV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Sgk_j-tY0LTU"},"execution_count":null,"outputs":[]}]}