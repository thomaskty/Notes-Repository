{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbd19d25",
   "metadata": {},
   "source": [
    "# Gaussian Mixture Models-Expectation Maximisation Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da02d124",
   "metadata": {},
   "source": [
    "**hard clustering**: clusters do not overlap \n",
    "\n",
    "**soft clustering** : strength of association between clusters and instances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a767bf",
   "metadata": {},
   "source": [
    "**mixture models** : \n",
    "- probabilistically grounded way of doing soft clustering\n",
    "- each cluster is considered as a distribution\n",
    "- each instances are considered as samples from the distribution.\n",
    "- parameters : means and covariances of distribution.\n",
    "- EM algorithm automatically discovers the parameters for the k clusters.\n",
    "\n",
    "GMM parameters are estimated from training data using the iterative Expectation-Maximization (EM) algorithm or Maximum *A Posteriori* (MAP) estimation from a well-trained prior model.\n",
    "\n",
    "**Gaussian mixture models** are a probabilistic model for representing normally distributed subpopulations within an overall population. \n",
    "\n",
    "Gaussian mixture model is parameterised by two types of values, the mixture component weights and the component means and variances/covariances. \n",
    "\n",
    "- if i know the source of each observation, estimation will be trivial\n",
    "- what if we don’t know the source?\n",
    "- if somebody gives the parameters of the underlying distributions, we could get the probabilities of each point belong to which clusters (posterior probabilities).\n",
    "- if we know  $p(x|b)$ - how typical is x under source b, we can estimate  $p(b|x)$ using bayes theorem.\n",
    "\n",
    "### EM Algorithm\n",
    "\n",
    "- start with randomly placed gaussians (given parameters)\n",
    "- Expectation step: for each point we color the points. $p(b|x)$  = does it look like it came from b gaussian (using bayes theorem)\n",
    "- Maximisation Step : adjust the parameters ( re-estimating the means and covariances of gaussians)\n",
    "\n",
    "### Gaussian Mixture Model\n",
    "\n",
    "- Data with D attributes, from gaussian sources $c_1, c_2, ..., c_k$\n",
    "- How typical is $x_i$ under source c : $p(x|c)$\n",
    "- How likely that $x_i$  came from c : $p(c|x)$\n",
    "- how important is $x_i$  for source c : weight of each point to each cluster.\n",
    "- reestimating weighted means and covariances.\n",
    "- prior : how many items assigned to c cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9ff313",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
